Loading data...
Vocab size: 10002
Time usage: 0:00:05
<bound method Module.parameters of Model(
  (embedding): Embedding(10002, 300, padding_idx=10001)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=768, out_features=4, bias=True)
)>
Iter:      0,  Train Loss:   1.4,  Train Acc: 34.38%,  Val Loss:   1.6,  Val Acc: 25.27%,  Time: 0:00:01 *
Iter:    100,  Train Loss:  0.81,  Train Acc: 70.31%,  Val Loss:  0.75,  Val Acc: 73.43%,  Time: 0:00:05 *
Iter:    200,  Train Loss:  0.54,  Train Acc: 76.56%,  Val Loss:  0.59,  Val Acc: 79.30%,  Time: 0:00:09 *
Iter:    300,  Train Loss:  0.74,  Train Acc: 71.88%,  Val Loss:  0.52,  Val Acc: 81.27%,  Time: 0:00:13 *
Iter:    400,  Train Loss:  0.61,  Train Acc: 79.69%,  Val Loss:  0.48,  Val Acc: 83.27%,  Time: 0:00:16 *
Iter:    500,  Train Loss:  0.65,  Train Acc: 78.12%,  Val Loss:  0.45,  Val Acc: 83.57%,  Time: 0:00:20 *
Iter:    600,  Train Loss:  0.53,  Train Acc: 79.69%,  Val Loss:  0.43,  Val Acc: 84.53%,  Time: 0:00:24 *
Iter:    700,  Train Loss:  0.73,  Train Acc: 70.31%,  Val Loss:  0.42,  Val Acc: 85.18%,  Time: 0:00:28 *
Iter:    800,  Train Loss:  0.44,  Train Acc: 82.81%,  Val Loss:  0.42,  Val Acc: 85.08%,  Time: 0:00:31 
Iter:    900,  Train Loss:  0.54,  Train Acc: 79.69%,  Val Loss:  0.39,  Val Acc: 86.08%,  Time: 0:00:35 *
Iter:   1000,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.38,  Val Acc: 86.40%,  Time: 0:00:39 *
Iter:   1100,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.39,  Val Acc: 86.18%,  Time: 0:00:42 
Iter:   1200,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.37,  Val Acc: 86.80%,  Time: 0:00:46 *
Iter:   1300,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 87.55%,  Time: 0:00:50 *
Iter:   1400,  Train Loss:  0.46,  Train Acc: 85.94%,  Val Loss:  0.35,  Val Acc: 87.62%,  Time: 0:00:55 *
Iter:   1500,  Train Loss:  0.92,  Train Acc: 71.88%,  Val Loss:  0.35,  Val Acc: 87.95%,  Time: 0:01:01 *
Iter:   1600,  Train Loss:  0.31,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 87.48%,  Time: 0:01:06 
Iter:   1700,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 87.38%,  Time: 0:01:11 
Iter:   1800,  Train Loss:  0.46,  Train Acc: 79.69%,  Val Loss:  0.36,  Val Acc: 87.15%,  Time: 0:01:16 
Iter:   1900,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.34,  Val Acc: 87.60%,  Time: 0:01:21 *
Iter:   2000,  Train Loss:  0.53,  Train Acc: 76.56%,  Val Loss:  0.34,  Val Acc: 88.02%,  Time: 0:01:26 *
Iter:   2100,  Train Loss:  0.32,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 88.20%,  Time: 0:01:32 *
Iter:   2200,  Train Loss:  0.58,  Train Acc: 79.69%,  Val Loss:  0.35,  Val Acc: 87.57%,  Time: 0:01:37 
Iter:   2300,  Train Loss:   0.2,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 88.02%,  Time: 0:01:42 
Iter:   2400,  Train Loss:  0.21,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 88.18%,  Time: 0:01:48 
Iter:   2500,  Train Loss:  0.25,  Train Acc: 85.94%,  Val Loss:  0.33,  Val Acc: 88.28%,  Time: 0:01:53 *
Iter:   2600,  Train Loss:  0.15,  Train Acc: 95.31%,  Val Loss:  0.34,  Val Acc: 88.25%,  Time: 0:01:58 
Iter:   2700,  Train Loss:  0.33,  Train Acc: 93.75%,  Val Loss:  0.34,  Val Acc: 88.07%,  Time: 0:02:04 
Iter:   2800,  Train Loss:  0.36,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 88.43%,  Time: 0:02:09 
Iter:   2900,  Train Loss:  0.22,  Train Acc: 95.31%,  Val Loss:  0.33,  Val Acc: 88.48%,  Time: 0:02:14 *
Iter:   3000,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 88.63%,  Time: 0:02:19 *
Iter:   3100,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.32,  Val Acc: 88.90%,  Time: 0:02:24 *
Iter:   3200,  Train Loss:  0.36,  Train Acc: 85.94%,  Val Loss:  0.32,  Val Acc: 88.95%,  Time: 0:02:29 *
Iter:   3300,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.31,  Val Acc: 89.33%,  Time: 0:02:34 *
Iter:   3400,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.31,  Val Acc: 89.33%,  Time: 0:02:39 
Iter:   3500,  Train Loss:  0.55,  Train Acc: 75.00%,  Val Loss:  0.32,  Val Acc: 88.92%,  Time: 0:02:45 
Iter:   3600,  Train Loss:  0.33,  Train Acc: 92.19%,  Val Loss:  0.32,  Val Acc: 88.85%,  Time: 0:02:50 
Iter:   3700,  Train Loss:  0.58,  Train Acc: 79.69%,  Val Loss:  0.31,  Val Acc: 89.17%,  Time: 0:02:55 
Iter:   3800,  Train Loss:   0.3,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 89.18%,  Time: 0:03:01 
Iter:   3900,  Train Loss:  0.35,  Train Acc: 82.81%,  Val Loss:  0.31,  Val Acc: 89.37%,  Time: 0:03:05 
Iter:   4000,  Train Loss:  0.17,  Train Acc: 92.19%,  Val Loss:  0.31,  Val Acc: 89.22%,  Time: 0:03:10 
Iter:   4100,  Train Loss:  0.39,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.20%,  Time: 0:03:16 
Iter:   4200,  Train Loss:  0.15,  Train Acc: 95.31%,  Val Loss:  0.32,  Val Acc: 89.20%,  Time: 0:03:21 
Iter:   4300,  Train Loss:  0.26,  Train Acc: 87.50%,  Val Loss:  0.32,  Val Acc: 88.95%,  Time: 0:03:26 
No optimization for a long time, auto-stopping...
Test Loss:  0.31,  Test Acc: 89.25%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       World     0.8985    0.9042    0.9014      1900
      Sports     0.9477    0.9637    0.9556      1900
    Business     0.8413    0.8647    0.8528      1900
    Sci/Tech     0.8824    0.8374    0.8593      1900

    accuracy                         0.8925      7600
   macro avg     0.8925    0.8925    0.8923      7600
weighted avg     0.8925    0.8925    0.8923      7600

Confusion Matrix...
[[1718   51   83   48]
 [  39 1831   23    7]
 [  80   20 1643  157]
 [  75   30  204 1591]]
Time usage: 0:00:01
