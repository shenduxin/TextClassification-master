Loading data...
Vocab size: 10002
Time usage: 0:00:02
<bound method Module.parameters of Model(
  (embedding): Embedding(10002, 300, padding_idx=10001)
  (conv_region): Conv2d(1, 250, kernel_size=(3, 300), stride=(1, 1))
  (conv): Conv2d(250, 250, kernel_size=(3, 1), stride=(1, 1))
  (max_pool): MaxPool2d(kernel_size=(3, 1), stride=2, padding=0, dilation=1, ceil_mode=False)
  (padding1): ZeroPad2d(padding=(0, 0, 1, 1), value=0.0)
  (padding2): ZeroPad2d(padding=(0, 0, 0, 1), value=0.0)
  (relu): ReLU()
  (fc): Linear(in_features=250, out_features=4, bias=True)
)>
Iter:      0,  Train Loss:   1.5,  Train Acc: 21.09%,  Val Loss:   2.0,  Val Acc: 25.00%,  Time: 0:00:01 *
Iter:    100,  Train Loss:  0.68,  Train Acc: 74.22%,  Val Loss:  0.74,  Val Acc: 71.00%,  Time: 0:00:03 *
Iter:    200,  Train Loss:  0.64,  Train Acc: 78.12%,  Val Loss:   0.6,  Val Acc: 77.50%,  Time: 0:00:06 *
Iter:    300,  Train Loss:  0.46,  Train Acc: 82.81%,  Val Loss:  0.49,  Val Acc: 81.77%,  Time: 0:00:09 *
Iter:    400,  Train Loss:  0.44,  Train Acc: 82.03%,  Val Loss:  0.51,  Val Acc: 80.83%,  Time: 0:00:11 
Iter:    500,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.44,  Val Acc: 83.95%,  Time: 0:00:14 *
Iter:    600,  Train Loss:  0.33,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 85.38%,  Time: 0:00:17 *
Iter:    700,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.39,  Val Acc: 85.97%,  Time: 0:00:20 *
Iter:    800,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:  0.41,  Val Acc: 84.98%,  Time: 0:00:22 
Iter:    900,  Train Loss:  0.46,  Train Acc: 83.59%,  Val Loss:  0.37,  Val Acc: 86.87%,  Time: 0:00:25 *
Iter:   1000,  Train Loss:  0.33,  Train Acc: 86.72%,  Val Loss:  0.38,  Val Acc: 86.32%,  Time: 0:00:28 
Iter:   1100,  Train Loss:  0.29,  Train Acc: 92.19%,  Val Loss:  0.34,  Val Acc: 87.87%,  Time: 0:00:30 *
Iter:   1200,  Train Loss:  0.26,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 87.27%,  Time: 0:00:32 
Iter:   1300,  Train Loss:   0.2,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 88.13%,  Time: 0:00:34 *
Iter:   1400,  Train Loss:  0.22,  Train Acc: 92.97%,  Val Loss:  0.34,  Val Acc: 87.95%,  Time: 0:00:36 
Iter:   1500,  Train Loss:  0.16,  Train Acc: 96.09%,  Val Loss:  0.34,  Val Acc: 87.87%,  Time: 0:00:38 
Iter:   1600,  Train Loss:  0.33,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 88.18%,  Time: 0:00:40 *
Iter:   1700,  Train Loss:  0.31,  Train Acc: 89.84%,  Val Loss:  0.34,  Val Acc: 88.37%,  Time: 0:00:42 
Iter:   1800,  Train Loss:  0.24,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 88.38%,  Time: 0:00:44 *
Iter:   1900,  Train Loss:  0.22,  Train Acc: 89.84%,  Val Loss:  0.37,  Val Acc: 87.38%,  Time: 0:00:46 
Iter:   2000,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 87.95%,  Time: 0:00:47 
Iter:   2100,  Train Loss:  0.13,  Train Acc: 94.53%,  Val Loss:  0.34,  Val Acc: 87.88%,  Time: 0:00:49 
Iter:   2200,  Train Loss:  0.19,  Train Acc: 94.53%,  Val Loss:  0.36,  Val Acc: 88.07%,  Time: 0:00:51 
Iter:   2300,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:  0.36,  Val Acc: 88.33%,  Time: 0:00:53 
Iter:   2400,  Train Loss:  0.21,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 88.02%,  Time: 0:00:55 
Iter:   2500,  Train Loss:  0.22,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 88.60%,  Time: 0:00:57 
Iter:   2600,  Train Loss:  0.21,  Train Acc: 89.84%,  Val Loss:  0.36,  Val Acc: 88.33%,  Time: 0:00:59 
Iter:   2700,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.88%,  Time: 0:01:01 
Iter:   2800,  Train Loss:  0.23,  Train Acc: 91.41%,  Val Loss:  0.34,  Val Acc: 88.42%,  Time: 0:01:03 
No optimization for a long time, auto-stopping...
Test Loss:  0.31,  Test Acc: 89.43%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       World     0.9155    0.8895    0.9023      1900
      Sports     0.9302    0.9611    0.9454      1900
    Business     0.8700    0.8453    0.8574      1900
    Sci/Tech     0.8612    0.8816    0.8713      1900

    accuracy                         0.8943      7600
   macro avg     0.8942    0.8943    0.8941      7600
weighted avg     0.8942    0.8943    0.8941      7600

Confusion Matrix...
[[1690   74   75   61]
 [  27 1826   31   16]
 [  74   27 1606  193]
 [  55   36  134 1675]]
Time usage: 0:00:00
