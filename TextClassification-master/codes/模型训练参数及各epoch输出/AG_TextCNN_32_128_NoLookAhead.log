Loading data...
Vocab size: 10002
Time usage: 0:00:02
<bound method Module.parameters of Model(
  (embedding): Embedding(10002, 300, padding_idx=10001)
  (convs): ModuleList(
    (0): Conv2d(1, 256, kernel_size=(2, 300), stride=(1, 1))
    (1): Conv2d(1, 256, kernel_size=(3, 300), stride=(1, 1))
    (2): Conv2d(1, 256, kernel_size=(4, 300), stride=(1, 1))
  )
  (dropout): Dropout(p=0.5, inplace=False)
  (fc): Linear(in_features=768, out_features=4, bias=True)
)>
Iter:      0,  Train Loss:   1.4,  Train Acc: 32.81%,  Val Loss:   1.4,  Val Acc: 27.98%,  Time: 0:00:01 *
Iter:    100,  Train Loss:  0.71,  Train Acc: 72.66%,  Val Loss:  0.64,  Val Acc: 76.15%,  Time: 0:00:04 *
Iter:    200,  Train Loss:  0.52,  Train Acc: 79.69%,  Val Loss:  0.52,  Val Acc: 81.00%,  Time: 0:00:08 *
Iter:    300,  Train Loss:  0.62,  Train Acc: 78.91%,  Val Loss:  0.45,  Val Acc: 83.83%,  Time: 0:00:12 *
Iter:    400,  Train Loss:  0.49,  Train Acc: 81.25%,  Val Loss:   0.5,  Val Acc: 81.83%,  Time: 0:00:16 
Iter:    500,  Train Loss:  0.42,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 85.53%,  Time: 0:00:19 *
Iter:    600,  Train Loss:  0.43,  Train Acc: 85.94%,  Val Loss:  0.41,  Val Acc: 85.10%,  Time: 0:00:23 
Iter:    700,  Train Loss:  0.35,  Train Acc: 87.50%,  Val Loss:  0.37,  Val Acc: 86.90%,  Time: 0:00:27 *
Iter:    800,  Train Loss:  0.36,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 86.85%,  Time: 0:00:31 
Iter:    900,  Train Loss:  0.43,  Train Acc: 83.59%,  Val Loss:  0.37,  Val Acc: 86.47%,  Time: 0:00:35 
Iter:   1000,  Train Loss:  0.34,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 87.47%,  Time: 0:00:38 *
Iter:   1100,  Train Loss:  0.35,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 87.57%,  Time: 0:00:42 
Iter:   1200,  Train Loss:   0.3,  Train Acc: 88.28%,  Val Loss:  0.36,  Val Acc: 87.40%,  Time: 0:00:46 
Iter:   1300,  Train Loss:  0.19,  Train Acc: 92.19%,  Val Loss:  0.37,  Val Acc: 87.23%,  Time: 0:00:50 
Iter:   1400,  Train Loss:  0.31,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 87.45%,  Time: 0:00:53 
Iter:   1500,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 87.72%,  Time: 0:00:57 
Iter:   1600,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:  0.35,  Val Acc: 88.18%,  Time: 0:01:01 
Iter:   1700,  Train Loss:  0.34,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 87.63%,  Time: 0:01:05 *
Iter:   1800,  Train Loss:  0.36,  Train Acc: 85.94%,  Val Loss:  0.36,  Val Acc: 87.70%,  Time: 0:01:08 
Iter:   1900,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:  0.38,  Val Acc: 87.50%,  Time: 0:01:12 
Iter:   2000,  Train Loss:  0.21,  Train Acc: 90.62%,  Val Loss:  0.34,  Val Acc: 88.07%,  Time: 0:01:16 *
Iter:   2100,  Train Loss:  0.12,  Train Acc: 97.66%,  Val Loss:  0.35,  Val Acc: 88.00%,  Time: 0:01:20 
Iter:   2200,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.36,  Val Acc: 88.07%,  Time: 0:01:24 
Iter:   2300,  Train Loss:  0.18,  Train Acc: 92.97%,  Val Loss:  0.35,  Val Acc: 88.27%,  Time: 0:01:27 
Iter:   2400,  Train Loss:  0.29,  Train Acc: 91.41%,  Val Loss:  0.35,  Val Acc: 88.30%,  Time: 0:01:31 
Iter:   2500,  Train Loss:  0.32,  Train Acc: 88.28%,  Val Loss:  0.35,  Val Acc: 88.03%,  Time: 0:01:35 
Iter:   2600,  Train Loss:  0.19,  Train Acc: 94.53%,  Val Loss:  0.35,  Val Acc: 88.73%,  Time: 0:01:39 
Iter:   2700,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.23%,  Time: 0:01:43 
Iter:   2800,  Train Loss:  0.24,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.80%,  Time: 0:01:47 
Iter:   2900,  Train Loss: 0.086,  Train Acc: 96.88%,  Val Loss:  0.37,  Val Acc: 88.12%,  Time: 0:01:50 
Iter:   3000,  Train Loss:   0.2,  Train Acc: 93.75%,  Val Loss:  0.37,  Val Acc: 88.60%,  Time: 0:01:52 
No optimization for a long time, auto-stopping...
Test Loss:  0.33,  Test Acc: 88.87%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       World     0.9105    0.9000    0.9052      1900
      Sports     0.9427    0.9605    0.9515      1900
    Business     0.8094    0.8874    0.8466      1900
    Sci/Tech     0.9002    0.8068    0.8510      1900

    accuracy                         0.8887      7600
   macro avg     0.8907    0.8887    0.8886      7600
weighted avg     0.8907    0.8887    0.8886      7600

Confusion Matrix...
[[1710   57   94   39]
 [  30 1825   37    8]
 [  68   23 1686  123]
 [  70   31  266 1533]]
Time usage: 0:00:00
