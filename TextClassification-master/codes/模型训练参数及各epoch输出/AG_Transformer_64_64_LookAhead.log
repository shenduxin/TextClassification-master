Loading data...
Vocab size: 10002
Time usage: 0:00:03
<bound method Module.parameters of Model(
  (embedding): Embedding(10002, 300, padding_idx=10001)
  (postion_embedding): Positional_Encoding(
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (encoder): Encoder(
    (attention): Multi_Head_Attention(
      (fc_Q): Linear(in_features=300, out_features=300, bias=True)
      (fc_K): Linear(in_features=300, out_features=300, bias=True)
      (fc_V): Linear(in_features=300, out_features=300, bias=True)
      (attention): Scaled_Dot_Product_Attention()
      (fc): Linear(in_features=300, out_features=300, bias=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
    )
    (feed_forward): Position_wise_Feed_Forward(
      (fc1): Linear(in_features=300, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=300, bias=True)
      (dropout): Dropout(p=0.5, inplace=False)
      (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
    )
  )
  (encoders): ModuleList(
    (0): Encoder(
      (attention): Multi_Head_Attention(
        (fc_Q): Linear(in_features=300, out_features=300, bias=True)
        (fc_K): Linear(in_features=300, out_features=300, bias=True)
        (fc_V): Linear(in_features=300, out_features=300, bias=True)
        (attention): Scaled_Dot_Product_Attention()
        (fc): Linear(in_features=300, out_features=300, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      )
      (feed_forward): Position_wise_Feed_Forward(
        (fc1): Linear(in_features=300, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=300, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      )
    )
    (1): Encoder(
      (attention): Multi_Head_Attention(
        (fc_Q): Linear(in_features=300, out_features=300, bias=True)
        (fc_K): Linear(in_features=300, out_features=300, bias=True)
        (fc_V): Linear(in_features=300, out_features=300, bias=True)
        (attention): Scaled_Dot_Product_Attention()
        (fc): Linear(in_features=300, out_features=300, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      )
      (feed_forward): Position_wise_Feed_Forward(
        (fc1): Linear(in_features=300, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=300, bias=True)
        (dropout): Dropout(p=0.5, inplace=False)
        (layer_norm): LayerNorm((300,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (fc1): Linear(in_features=19200, out_features=4, bias=True)
)>
Iter:      0,  Train Loss:   1.6,  Train Acc: 18.75%,  Val Loss:   7.9,  Val Acc: 25.00%,  Time: 0:00:01 *
Iter:    100,  Train Loss:   1.3,  Train Acc: 43.75%,  Val Loss:   1.3,  Val Acc: 39.77%,  Time: 0:00:05 *
Iter:    200,  Train Loss:   1.2,  Train Acc: 43.75%,  Val Loss:   1.2,  Val Acc: 48.78%,  Time: 0:00:08 *
Iter:    300,  Train Loss:   1.2,  Train Acc: 53.12%,  Val Loss:   1.1,  Val Acc: 54.17%,  Time: 0:00:12 *
Iter:    400,  Train Loss:   1.1,  Train Acc: 56.25%,  Val Loss:   1.0,  Val Acc: 61.00%,  Time: 0:00:16 *
Iter:    500,  Train Loss:   0.9,  Train Acc: 65.62%,  Val Loss:  0.87,  Val Acc: 67.47%,  Time: 0:00:19 *
Iter:    600,  Train Loss:  0.81,  Train Acc: 67.19%,  Val Loss:  0.79,  Val Acc: 70.85%,  Time: 0:00:23 *
Iter:    700,  Train Loss:  0.95,  Train Acc: 67.19%,  Val Loss:   0.8,  Val Acc: 71.30%,  Time: 0:00:27 
Iter:    800,  Train Loss:   0.9,  Train Acc: 64.06%,  Val Loss:  0.79,  Val Acc: 71.47%,  Time: 0:00:30 *
Iter:    900,  Train Loss:  0.78,  Train Acc: 76.56%,  Val Loss:  0.64,  Val Acc: 77.45%,  Time: 0:00:34 *
Iter:   1000,  Train Loss:  0.67,  Train Acc: 75.00%,  Val Loss:  0.62,  Val Acc: 78.00%,  Time: 0:00:38 *
Iter:   1100,  Train Loss:  0.65,  Train Acc: 73.44%,  Val Loss:  0.63,  Val Acc: 77.62%,  Time: 0:00:42 
Iter:   1200,  Train Loss:  0.91,  Train Acc: 73.44%,  Val Loss:  0.56,  Val Acc: 80.48%,  Time: 0:00:45 *
Iter:   1300,  Train Loss:  0.52,  Train Acc: 82.81%,  Val Loss:  0.54,  Val Acc: 80.07%,  Time: 0:00:49 *
Iter:   1400,  Train Loss:  0.78,  Train Acc: 73.44%,  Val Loss:  0.57,  Val Acc: 78.97%,  Time: 0:00:53 
Iter:   1500,  Train Loss:  0.78,  Train Acc: 64.06%,  Val Loss:  0.56,  Val Acc: 80.18%,  Time: 0:00:57 
Iter:   1600,  Train Loss:  0.61,  Train Acc: 76.56%,  Val Loss:  0.52,  Val Acc: 81.25%,  Time: 0:01:00 *
Iter:   1700,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.51,  Val Acc: 81.10%,  Time: 0:01:04 *
Iter:   1800,  Train Loss:  0.62,  Train Acc: 79.69%,  Val Loss:  0.49,  Val Acc: 82.63%,  Time: 0:01:08 *
Iter:   1900,  Train Loss:  0.53,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 83.87%,  Time: 0:01:12 *
Iter:   2000,  Train Loss:  0.55,  Train Acc: 79.69%,  Val Loss:  0.48,  Val Acc: 83.18%,  Time: 0:01:16 
Iter:   2100,  Train Loss:  0.47,  Train Acc: 81.25%,  Val Loss:  0.47,  Val Acc: 83.02%,  Time: 0:01:19 *
Iter:   2200,  Train Loss:  0.67,  Train Acc: 76.56%,  Val Loss:  0.46,  Val Acc: 83.18%,  Time: 0:01:23 *
Iter:   2300,  Train Loss:  0.46,  Train Acc: 82.81%,  Val Loss:  0.45,  Val Acc: 83.60%,  Time: 0:01:26 *
Iter:   2400,  Train Loss:  0.57,  Train Acc: 79.69%,  Val Loss:  0.48,  Val Acc: 82.78%,  Time: 0:01:30 
Iter:   2500,  Train Loss:  0.57,  Train Acc: 81.25%,  Val Loss:  0.46,  Val Acc: 83.22%,  Time: 0:01:34 
Iter:   2600,  Train Loss:  0.43,  Train Acc: 78.12%,  Val Loss:  0.47,  Val Acc: 83.57%,  Time: 0:01:37 
Iter:   2700,  Train Loss:  0.51,  Train Acc: 79.69%,  Val Loss:  0.44,  Val Acc: 83.82%,  Time: 0:01:41 *
Iter:   2800,  Train Loss:  0.41,  Train Acc: 82.81%,  Val Loss:  0.45,  Val Acc: 83.30%,  Time: 0:01:45 
Iter:   2900,  Train Loss:  0.48,  Train Acc: 84.38%,  Val Loss:  0.45,  Val Acc: 83.85%,  Time: 0:01:49 
Iter:   3000,  Train Loss:  0.59,  Train Acc: 78.12%,  Val Loss:  0.44,  Val Acc: 84.58%,  Time: 0:01:52 
Iter:   3100,  Train Loss:  0.51,  Train Acc: 81.25%,  Val Loss:  0.43,  Val Acc: 84.47%,  Time: 0:01:56 *
Iter:   3200,  Train Loss:  0.45,  Train Acc: 84.38%,  Val Loss:  0.41,  Val Acc: 85.52%,  Time: 0:02:00 *
Iter:   3300,  Train Loss:   0.5,  Train Acc: 81.25%,  Val Loss:  0.41,  Val Acc: 86.17%,  Time: 0:02:03 *
Iter:   3400,  Train Loss:  0.58,  Train Acc: 76.56%,  Val Loss:   0.4,  Val Acc: 86.37%,  Time: 0:02:07 *
Iter:   3500,  Train Loss:  0.73,  Train Acc: 73.44%,  Val Loss:  0.41,  Val Acc: 85.70%,  Time: 0:02:11 
Iter:   3600,  Train Loss:  0.56,  Train Acc: 78.12%,  Val Loss:  0.41,  Val Acc: 86.13%,  Time: 0:02:15 
Iter:   3700,  Train Loss:  0.77,  Train Acc: 70.31%,  Val Loss:  0.42,  Val Acc: 85.62%,  Time: 0:02:18 
Iter:   3800,  Train Loss:   0.6,  Train Acc: 79.69%,  Val Loss:  0.41,  Val Acc: 86.35%,  Time: 0:02:22 
Iter:   3900,  Train Loss:  0.49,  Train Acc: 82.81%,  Val Loss:  0.39,  Val Acc: 86.28%,  Time: 0:02:25 *
Iter:   4000,  Train Loss:  0.39,  Train Acc: 84.38%,  Val Loss:   0.4,  Val Acc: 85.85%,  Time: 0:02:29 
Iter:   4100,  Train Loss:  0.62,  Train Acc: 71.88%,  Val Loss:   0.4,  Val Acc: 86.18%,  Time: 0:02:33 
Iter:   4200,  Train Loss:  0.39,  Train Acc: 82.81%,  Val Loss:  0.39,  Val Acc: 86.53%,  Time: 0:02:37 *
Iter:   4300,  Train Loss:  0.63,  Train Acc: 75.00%,  Val Loss:   0.4,  Val Acc: 86.22%,  Time: 0:02:40 
Iter:   4400,  Train Loss:   0.7,  Train Acc: 75.00%,  Val Loss:  0.45,  Val Acc: 84.48%,  Time: 0:02:44 
Iter:   4500,  Train Loss:  0.45,  Train Acc: 87.50%,  Val Loss:  0.38,  Val Acc: 87.10%,  Time: 0:02:48 *
Iter:   4600,  Train Loss:  0.42,  Train Acc: 87.50%,  Val Loss:   0.4,  Val Acc: 86.65%,  Time: 0:02:52 
Iter:   4700,  Train Loss:  0.62,  Train Acc: 79.69%,  Val Loss:   0.4,  Val Acc: 86.13%,  Time: 0:02:56 
Iter:   4800,  Train Loss:  0.58,  Train Acc: 76.56%,  Val Loss:   0.4,  Val Acc: 86.30%,  Time: 0:02:59 
Iter:   4900,  Train Loss:   0.4,  Train Acc: 84.38%,  Val Loss:  0.38,  Val Acc: 86.95%,  Time: 0:03:03 *
Iter:   5000,  Train Loss:  0.54,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 87.50%,  Time: 0:03:07 *
Iter:   5100,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 87.05%,  Time: 0:03:11 *
Iter:   5200,  Train Loss:   0.4,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 87.13%,  Time: 0:03:14 
Iter:   5300,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 86.88%,  Time: 0:03:18 
Iter:   5400,  Train Loss:   0.4,  Train Acc: 82.81%,  Val Loss:  0.38,  Val Acc: 86.83%,  Time: 0:03:21 
Iter:   5500,  Train Loss:  0.62,  Train Acc: 71.88%,  Val Loss:  0.37,  Val Acc: 87.37%,  Time: 0:03:25 
Iter:   5600,  Train Loss:  0.69,  Train Acc: 70.31%,  Val Loss:  0.36,  Val Acc: 87.67%,  Time: 0:03:28 *
Iter:   5700,  Train Loss:  0.42,  Train Acc: 79.69%,  Val Loss:  0.38,  Val Acc: 87.32%,  Time: 0:03:32 
Iter:   5800,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:   0.4,  Val Acc: 86.82%,  Time: 0:03:36 
Iter:   5900,  Train Loss:  0.58,  Train Acc: 76.56%,  Val Loss:  0.37,  Val Acc: 87.77%,  Time: 0:03:39 
Iter:   6000,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 87.22%,  Time: 0:03:43 
Iter:   6100,  Train Loss:  0.23,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 87.38%,  Time: 0:03:47 
Iter:   6200,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.38,  Val Acc: 87.03%,  Time: 0:03:50 
Iter:   6300,  Train Loss:  0.39,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 87.90%,  Time: 0:03:54 
Iter:   6400,  Train Loss:  0.59,  Train Acc: 82.81%,  Val Loss:  0.37,  Val Acc: 87.23%,  Time: 0:03:58 
Iter:   6500,  Train Loss:  0.51,  Train Acc: 76.56%,  Val Loss:  0.36,  Val Acc: 87.62%,  Time: 0:04:01 *
Iter:   6600,  Train Loss:  0.25,  Train Acc: 92.19%,  Val Loss:  0.37,  Val Acc: 87.58%,  Time: 0:04:05 
Iter:   6700,  Train Loss:  0.25,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 87.82%,  Time: 0:04:08 
Iter:   6800,  Train Loss:   0.5,  Train Acc: 82.81%,  Val Loss:  0.36,  Val Acc: 87.78%,  Time: 0:04:12 
Iter:   6900,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 87.73%,  Time: 0:04:16 *
Iter:   7000,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.36,  Val Acc: 88.17%,  Time: 0:04:19 *
Iter:   7100,  Train Loss:  0.57,  Train Acc: 84.38%,  Val Loss:  0.38,  Val Acc: 87.43%,  Time: 0:04:23 
Iter:   7200,  Train Loss:  0.34,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 88.20%,  Time: 0:04:27 
Iter:   7300,  Train Loss:  0.27,  Train Acc: 89.06%,  Val Loss:  0.35,  Val Acc: 88.18%,  Time: 0:04:30 *
Iter:   7400,  Train Loss:  0.49,  Train Acc: 84.38%,  Val Loss:  0.35,  Val Acc: 88.30%,  Time: 0:04:34 *
Iter:   7500,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.18%,  Time: 0:04:38 
Iter:   7600,  Train Loss:  0.46,  Train Acc: 84.38%,  Val Loss:  0.37,  Val Acc: 88.18%,  Time: 0:04:41 
Iter:   7700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.36,  Val Acc: 87.58%,  Time: 0:04:45 
Iter:   7800,  Train Loss:  0.33,  Train Acc: 87.50%,  Val Loss:  0.36,  Val Acc: 87.97%,  Time: 0:04:48 
Iter:   7900,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.35,  Val Acc: 88.32%,  Time: 0:04:52 
Iter:   8000,  Train Loss:  0.49,  Train Acc: 82.81%,  Val Loss:  0.38,  Val Acc: 87.03%,  Time: 0:04:56 
Iter:   8100,  Train Loss:   0.3,  Train Acc: 93.75%,  Val Loss:  0.36,  Val Acc: 87.73%,  Time: 0:04:59 
Iter:   8200,  Train Loss:  0.58,  Train Acc: 85.94%,  Val Loss:  0.37,  Val Acc: 87.67%,  Time: 0:05:03 
Iter:   8300,  Train Loss:  0.49,  Train Acc: 82.81%,  Val Loss:  0.39,  Val Acc: 86.55%,  Time: 0:05:06 
Iter:   8400,  Train Loss:  0.47,  Train Acc: 79.69%,  Val Loss:  0.36,  Val Acc: 88.23%,  Time: 0:05:10 
Iter:   8500,  Train Loss:  0.36,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 88.27%,  Time: 0:05:14 *
Iter:   8600,  Train Loss:   0.2,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 88.93%,  Time: 0:05:17 *
Iter:   8700,  Train Loss:  0.58,  Train Acc: 76.56%,  Val Loss:  0.34,  Val Acc: 88.73%,  Time: 0:05:21 
Iter:   8800,  Train Loss:  0.36,  Train Acc: 82.81%,  Val Loss:  0.35,  Val Acc: 88.45%,  Time: 0:05:25 
Iter:   8900,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.37,  Val Acc: 88.00%,  Time: 0:05:28 
Iter:   9000,  Train Loss:  0.38,  Train Acc: 82.81%,  Val Loss:  0.35,  Val Acc: 88.12%,  Time: 0:05:32 
Iter:   9100,  Train Loss:  0.33,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.25%,  Time: 0:05:36 
Iter:   9200,  Train Loss:  0.35,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 88.65%,  Time: 0:05:39 *
Iter:   9300,  Train Loss:  0.53,  Train Acc: 82.81%,  Val Loss:  0.34,  Val Acc: 88.85%,  Time: 0:05:43 
Iter:   9400,  Train Loss:  0.32,  Train Acc: 92.19%,  Val Loss:  0.36,  Val Acc: 88.40%,  Time: 0:05:47 
Iter:   9500,  Train Loss:  0.34,  Train Acc: 82.81%,  Val Loss:  0.35,  Val Acc: 88.37%,  Time: 0:05:50 
Iter:   9600,  Train Loss:  0.49,  Train Acc: 81.25%,  Val Loss:  0.34,  Val Acc: 88.50%,  Time: 0:05:54 
Iter:   9700,  Train Loss:  0.42,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 87.93%,  Time: 0:05:58 
Iter:   9800,  Train Loss:  0.15,  Train Acc: 95.31%,  Val Loss:  0.38,  Val Acc: 87.90%,  Time: 0:06:02 
Iter:   9900,  Train Loss:  0.38,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.52%,  Time: 0:06:05 
Iter:  10000,  Train Loss:  0.37,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 88.73%,  Time: 0:06:09 
Iter:  10100,  Train Loss:  0.41,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.08%,  Time: 0:06:12 
Iter:  10200,  Train Loss:  0.44,  Train Acc: 82.81%,  Val Loss:  0.33,  Val Acc: 88.92%,  Time: 0:06:16 
Iter:  10300,  Train Loss:  0.43,  Train Acc: 82.81%,  Val Loss:  0.34,  Val Acc: 88.70%,  Time: 0:06:20 
Iter:  10400,  Train Loss:  0.38,  Train Acc: 85.94%,  Val Loss:  0.35,  Val Acc: 88.62%,  Time: 0:06:23 
Iter:  10500,  Train Loss:   0.3,  Train Acc: 92.19%,  Val Loss:  0.35,  Val Acc: 88.57%,  Time: 0:06:27 
Iter:  10600,  Train Loss:  0.25,  Train Acc: 89.06%,  Val Loss:  0.36,  Val Acc: 88.17%,  Time: 0:06:31 
Iter:  10700,  Train Loss:  0.44,  Train Acc: 84.38%,  Val Loss:  0.36,  Val Acc: 88.08%,  Time: 0:06:34 
Iter:  10800,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.62%,  Time: 0:06:38 
Iter:  10900,  Train Loss:  0.44,  Train Acc: 81.25%,  Val Loss:  0.36,  Val Acc: 88.78%,  Time: 0:06:41 
Iter:  11000,  Train Loss:  0.28,  Train Acc: 90.62%,  Val Loss:  0.35,  Val Acc: 88.73%,  Time: 0:06:45 
Iter:  11100,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.34,  Val Acc: 88.87%,  Time: 0:06:49 
Iter:  11200,  Train Loss:  0.27,  Train Acc: 92.19%,  Val Loss:  0.38,  Val Acc: 88.18%,  Time: 0:06:52 
No optimization for a long time, auto-stopping...
Test Loss:  0.34,  Test Acc: 88.79%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       World     0.8960    0.8932    0.8946      1900
      Sports     0.9387    0.9584    0.9484      1900
    Business     0.8649    0.8358    0.8501      1900
    Sci/Tech     0.8508    0.8642    0.8574      1900

    accuracy                         0.8879      7600
   macro avg     0.8876    0.8879    0.8876      7600
weighted avg     0.8876    0.8879    0.8876      7600

Confusion Matrix...
[[1697   62   73   68]
 [  34 1821   27   18]
 [  87   23 1588  202]
 [  76   34  148 1642]]
Time usage: 0:00:01
