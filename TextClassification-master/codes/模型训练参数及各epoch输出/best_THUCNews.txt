Loading data...
180000it [00:35, 5110.64it/s]
10000it [00:01, 5305.10it/s]
10000it [00:01, 5326.96it/s]
Time usage: 0:00:39
<bound method Module.parameters of Model(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(18000, 768, padding_idx=0)
      (position_embeddings): Embedding(513, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (fc): Linear(in_features=768, out_features=10, bias=True)
)>
Epoch:   0%|                                                                                                                                                              | 0/3 [00:00<?, ?it/s]Iter:      0,  Train Loss:   2.5,  Train Acc: 10.16%,  Val Loss:   2.3,  Val Acc: 11.94%,  Time: 0:00:13 *
Iter:    100,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.33,  Val Acc: 89.72%,  Time: 0:01:12 *
Iter:    200,  Train Loss:  0.37,  Train Acc: 86.72%,  Val Loss:  0.28,  Val Acc: 91.44%,  Time: 0:02:11 *
Iter:    300,  Train Loss:  0.29,  Train Acc: 89.84%,  Val Loss:  0.28,  Val Acc: 91.34%,  Time: 0:03:10 *
Iter:    400,  Train Loss:  0.37,  Train Acc: 88.28%,  Val Loss:  0.24,  Val Acc: 92.69%,  Time: 0:04:09 *
Iter:    500,  Train Loss:  0.26,  Train Acc: 91.41%,  Val Loss:  0.23,  Val Acc: 92.49%,  Time: 0:05:08 *
Iter:    600,  Train Loss:  0.32,  Train Acc: 90.62%,  Val Loss:  0.22,  Val Acc: 93.00%,  Time: 0:06:07 *
Iter:    700,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.22,  Val Acc: 93.08%,  Time: 0:07:07 *
Iter:    800,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.21,  Val Acc: 93.07%,  Time: 0:08:06 *
Iter:    900,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.21,  Val Acc: 92.95%,  Time: 0:09:04 
Iter:   1000,  Train Loss:  0.19,  Train Acc: 93.75%,  Val Loss:  0.21,  Val Acc: 92.86%,  Time: 0:10:02 
Iter:   1100,  Train Loss:  0.23,  Train Acc: 93.75%,  Val Loss:   0.2,  Val Acc: 93.19%,  Time: 0:11:01 *
Iter:   1200,  Train Loss:  0.24,  Train Acc: 92.19%,  Val Loss:   0.2,  Val Acc: 93.24%,  Time: 0:12:00 *
Iter:   1300,  Train Loss:  0.21,  Train Acc: 91.41%,  Val Loss:   0.2,  Val Acc: 93.78%,  Time: 0:12:58 
Iter:   1400,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.19,  Val Acc: 93.53%,  Time: 0:13:58 *
Epoch:  33%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨ƒ                                                                                                   | 1/3 [13:59<27:59, 839.95s/it]Iter:   1500,  Train Loss:  0.15,  Train Acc: 95.31%,  Val Loss:   0.2,  Val Acc: 93.40%,  Time: 0:14:55 
Iter:   1600,  Train Loss:  0.24,  Train Acc: 92.97%,  Val Loss:   0.2,  Val Acc: 93.76%,  Time: 0:15:53 
Iter:   1700,  Train Loss:  0.26,  Train Acc: 94.53%,  Val Loss:   0.2,  Val Acc: 93.75%,  Time: 0:16:52 
Iter:   1800,  Train Loss:   0.2,  Train Acc: 94.53%,  Val Loss:  0.19,  Val Acc: 93.80%,  Time: 0:17:51 *
Iter:   1900,  Train Loss:  0.12,  Train Acc: 96.09%,  Val Loss:   0.2,  Val Acc: 93.55%,  Time: 0:18:49 
Iter:   2000,  Train Loss:   0.2,  Train Acc: 96.09%,  Val Loss:   0.2,  Val Acc: 93.41%,  Time: 0:19:47 
Iter:   2100,  Train Loss:  0.13,  Train Acc: 93.75%,  Val Loss:   0.2,  Val Acc: 93.65%,  Time: 0:20:45 
Iter:   2200,  Train Loss: 0.088,  Train Acc: 96.88%,  Val Loss:   0.2,  Val Acc: 93.74%,  Time: 0:21:44 
Iter:   2300,  Train Loss:  0.08,  Train Acc: 96.88%,  Val Loss:  0.21,  Val Acc: 93.50%,  Time: 0:22:42 
Iter:   2400,  Train Loss:  0.12,  Train Acc: 95.31%,  Val Loss:  0.19,  Val Acc: 93.82%,  Time: 0:23:40 
Iter:   2500,  Train Loss:  0.14,  Train Acc: 96.09%,  Val Loss:  0.19,  Val Acc: 93.82%,  Time: 0:24:38 
Iter:   2600,  Train Loss:  0.16,  Train Acc: 92.97%,  Val Loss:  0.19,  Val Acc: 93.90%,  Time: 0:25:37 *
Iter:   2700,  Train Loss:  0.14,  Train Acc: 93.75%,  Val Loss:  0.19,  Val Acc: 93.92%,  Time: 0:26:35 
Iter:   2800,  Train Loss: 0.086,  Train Acc: 99.22%,  Val Loss:  0.19,  Val Acc: 93.85%,  Time: 0:27:33 
Epoch:  67%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨†                                                 | 2/3 [27:38<13:53, 833.67s/it]Iter:   2900,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.19,  Val Acc: 94.07%,  Time: 0:28:31 
Iter:   3000,  Train Loss:  0.08,  Train Acc: 97.66%,  Val Loss:   0.2,  Val Acc: 93.60%,  Time: 0:29:29 
Iter:   3100,  Train Loss: 0.043,  Train Acc: 98.44%,  Val Loss:   0.2,  Val Acc: 93.64%,  Time: 0:30:27 
Iter:   3200,  Train Loss:  0.17,  Train Acc: 95.31%,  Val Loss:  0.21,  Val Acc: 93.48%,  Time: 0:31:25 
Iter:   3300,  Train Loss:  0.12,  Train Acc: 94.53%,  Val Loss:   0.2,  Val Acc: 93.83%,  Time: 0:32:23 
Iter:   3400,  Train Loss: 0.098,  Train Acc: 96.09%,  Val Loss:   0.2,  Val Acc: 94.02%,  Time: 0:33:22 
Iter:   3500,  Train Loss: 0.072,  Train Acc: 98.44%,  Val Loss:   0.2,  Val Acc: 94.03%,  Time: 0:34:20 
Iter:   3600,  Train Loss: 0.051,  Train Acc: 97.66%,  Val Loss:  0.21,  Val Acc: 93.83%,  Time: 0:35:18 
No optimization for a long time, auto-stopping...
Test Loss:  0.18,  Test Acc: 94.51%
Precision, Recall and F1-Score...
               precision    recall  f1-score   support

      finance     0.9493    0.9170    0.9329      1000
       realty     0.9711    0.9420    0.9563      1000
       stocks     0.8980    0.9070    0.9025      1000
    education     0.9699    0.9680    0.9690      1000
      science     0.9029    0.9300    0.9163      1000
      society     0.9338    0.9450    0.9394      1000
     politics     0.9272    0.9300    0.9286      1000
       sports     0.9772    0.9870    0.9821      1000
         game     0.9697    0.9600    0.9648      1000
entertainment     0.9545    0.9650    0.9597      1000

     accuracy                         0.9451     10000
    macro avg     0.9454    0.9451    0.9452     10000
 weighted avg     0.9454    0.9451    0.9452     10000

Confusion Matrix...
[[917   9  50   1   7   6   8   1   1   0]
 [ 11 942  16   2   5   9   8   3   0   4]
 [ 31   8 907   0  28   3  17   2   2   2]
 [  2   1   2 968   1  13   6   2   0   5]
 [  0   2  11   3 930  10   7   1  23  13]
 [  1   5   1  11   7 945  18   0   2  10]
 [  3   1  18   8  19  16 930   1   0   4]
 [  0   1   1   0   2   2   3 987   0   4]
 [  0   0   2   1  26   4   3   0 960   4]
 [  1   1   2   4   5   4   3  13   2 965]]
Time usage: 0:00:12
