Loading data...
Vocab size: 10002
Time usage: 0:00:11
<bound method Module.parameters of Model(
  (embedding): Embedding(10002, 300, padding_idx=10001)
  (embedding_ngram2): Embedding(250499, 300)
  (embedding_ngram3): Embedding(250499, 300)
  (dropout): Dropout(p=0.5, inplace=False)
  (fc1): Linear(in_features=900, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=4, bias=True)
)>
Iter:      0,  Train Loss:   1.5,  Train Acc: 26.56%,  Val Loss:   1.5,  Val Acc: 24.93%,  Time: 0:00:03 *
Iter:    100,  Train Loss:   1.1,  Train Acc: 56.25%,  Val Loss:   1.2,  Val Acc: 48.30%,  Time: 0:00:08 *
Iter:    200,  Train Loss:  0.79,  Train Acc: 73.44%,  Val Loss:  0.86,  Val Acc: 68.97%,  Time: 0:00:14 *
Iter:    300,  Train Loss:  0.82,  Train Acc: 71.88%,  Val Loss:   0.7,  Val Acc: 72.85%,  Time: 0:00:19 *
Iter:    400,  Train Loss:  0.73,  Train Acc: 75.00%,  Val Loss:  0.56,  Val Acc: 79.57%,  Time: 0:00:25 *
Iter:    500,  Train Loss:  0.72,  Train Acc: 75.00%,  Val Loss:  0.51,  Val Acc: 81.10%,  Time: 0:00:30 *
Iter:    600,  Train Loss:  0.59,  Train Acc: 81.25%,  Val Loss:  0.48,  Val Acc: 82.30%,  Time: 0:00:35 *
Iter:    700,  Train Loss:  0.63,  Train Acc: 78.12%,  Val Loss:  0.48,  Val Acc: 81.78%,  Time: 0:00:41 *
Iter:    800,  Train Loss:  0.47,  Train Acc: 81.25%,  Val Loss:  0.42,  Val Acc: 84.70%,  Time: 0:00:46 *
Iter:    900,  Train Loss:  0.58,  Train Acc: 79.69%,  Val Loss:  0.41,  Val Acc: 85.10%,  Time: 0:00:52 *
Iter:   1000,  Train Loss:  0.49,  Train Acc: 81.25%,  Val Loss:   0.4,  Val Acc: 86.58%,  Time: 0:00:57 *
Iter:   1100,  Train Loss:  0.47,  Train Acc: 82.81%,  Val Loss:  0.37,  Val Acc: 87.38%,  Time: 0:01:02 *
Iter:   1200,  Train Loss:  0.49,  Train Acc: 82.81%,  Val Loss:  0.37,  Val Acc: 86.50%,  Time: 0:01:06 
Iter:   1300,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.34,  Val Acc: 88.05%,  Time: 0:01:11 *
Iter:   1400,  Train Loss:  0.52,  Train Acc: 84.38%,  Val Loss:  0.34,  Val Acc: 88.00%,  Time: 0:01:14 
Iter:   1500,  Train Loss:  0.67,  Train Acc: 76.56%,  Val Loss:  0.34,  Val Acc: 88.40%,  Time: 0:01:19 *
Iter:   1600,  Train Loss:  0.42,  Train Acc: 81.25%,  Val Loss:  0.37,  Val Acc: 86.92%,  Time: 0:01:22 
Iter:   1700,  Train Loss:  0.33,  Train Acc: 87.50%,  Val Loss:  0.33,  Val Acc: 88.30%,  Time: 0:01:28 *
Iter:   1800,  Train Loss:  0.54,  Train Acc: 81.25%,  Val Loss:  0.33,  Val Acc: 88.40%,  Time: 0:01:31 
Iter:   1900,  Train Loss:  0.39,  Train Acc: 85.94%,  Val Loss:  0.31,  Val Acc: 89.27%,  Time: 0:01:36 *
Iter:   2000,  Train Loss:  0.39,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 89.23%,  Time: 0:01:42 *
Iter:   2100,  Train Loss:  0.29,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 89.48%,  Time: 0:01:47 *
Iter:   2200,  Train Loss:  0.48,  Train Acc: 82.81%,  Val Loss:  0.33,  Val Acc: 88.37%,  Time: 0:01:50 
Iter:   2300,  Train Loss:  0.17,  Train Acc: 96.88%,  Val Loss:   0.3,  Val Acc: 89.27%,  Time: 0:01:53 
Iter:   2400,  Train Loss:  0.35,  Train Acc: 81.25%,  Val Loss:   0.3,  Val Acc: 89.10%,  Time: 0:01:59 *
Iter:   2500,  Train Loss:  0.31,  Train Acc: 89.06%,  Val Loss:  0.31,  Val Acc: 88.40%,  Time: 0:02:02 
Iter:   2600,  Train Loss:  0.19,  Train Acc: 90.62%,  Val Loss:  0.29,  Val Acc: 89.60%,  Time: 0:02:07 *
Iter:   2700,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.32,  Val Acc: 88.63%,  Time: 0:02:11 
Iter:   2800,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 89.25%,  Time: 0:02:14 
Iter:   2900,  Train Loss:  0.29,  Train Acc: 89.06%,  Val Loss:   0.3,  Val Acc: 89.15%,  Time: 0:02:17 
Iter:   3000,  Train Loss:  0.28,  Train Acc: 87.50%,  Val Loss:  0.29,  Val Acc: 89.60%,  Time: 0:02:20 
Iter:   3100,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.29,  Val Acc: 89.68%,  Time: 0:02:27 *
Iter:   3200,  Train Loss:  0.33,  Train Acc: 85.94%,  Val Loss:  0.28,  Val Acc: 89.92%,  Time: 0:02:35 *
Iter:   3300,  Train Loss:  0.41,  Train Acc: 84.38%,  Val Loss:  0.29,  Val Acc: 89.50%,  Time: 0:02:41 
Iter:   3400,  Train Loss:  0.37,  Train Acc: 84.38%,  Val Loss:  0.27,  Val Acc: 90.20%,  Time: 0:02:49 *
Iter:   3500,  Train Loss:  0.58,  Train Acc: 76.56%,  Val Loss:  0.28,  Val Acc: 89.68%,  Time: 0:02:55 
Iter:   3600,  Train Loss:   0.3,  Train Acc: 82.81%,  Val Loss:   0.3,  Val Acc: 89.52%,  Time: 0:03:00 
Iter:   3700,  Train Loss:  0.42,  Train Acc: 84.38%,  Val Loss:  0.28,  Val Acc: 89.68%,  Time: 0:03:06 
Iter:   3800,  Train Loss:  0.23,  Train Acc: 96.88%,  Val Loss:  0.28,  Val Acc: 89.58%,  Time: 0:03:12 
Iter:   3900,  Train Loss:  0.28,  Train Acc: 93.75%,  Val Loss:  0.27,  Val Acc: 90.32%,  Time: 0:03:20 *
Iter:   4000,  Train Loss:  0.25,  Train Acc: 90.62%,  Val Loss:  0.27,  Val Acc: 90.10%,  Time: 0:03:26 
Iter:   4100,  Train Loss:  0.36,  Train Acc: 84.38%,  Val Loss:  0.28,  Val Acc: 89.62%,  Time: 0:03:32 
Iter:   4200,  Train Loss:  0.17,  Train Acc: 93.75%,  Val Loss:  0.29,  Val Acc: 89.20%,  Time: 0:03:38 
Iter:   4300,  Train Loss:  0.22,  Train Acc: 93.75%,  Val Loss:  0.27,  Val Acc: 90.23%,  Time: 0:03:44 
Iter:   4400,  Train Loss:  0.36,  Train Acc: 87.50%,  Val Loss:   0.3,  Val Acc: 89.35%,  Time: 0:03:50 
Iter:   4500,  Train Loss:  0.35,  Train Acc: 85.94%,  Val Loss:  0.29,  Val Acc: 89.62%,  Time: 0:03:55 
Iter:   4600,  Train Loss:  0.28,  Train Acc: 84.38%,  Val Loss:  0.27,  Val Acc: 90.30%,  Time: 0:04:01 
Iter:   4700,  Train Loss:  0.18,  Train Acc: 96.88%,  Val Loss:  0.27,  Val Acc: 89.80%,  Time: 0:04:07 
Iter:   4800,  Train Loss:  0.31,  Train Acc: 87.50%,  Val Loss:  0.27,  Val Acc: 90.32%,  Time: 0:04:13 
Iter:   4900,  Train Loss:  0.24,  Train Acc: 93.75%,  Val Loss:  0.26,  Val Acc: 90.58%,  Time: 0:04:21 *
Iter:   5000,  Train Loss:  0.36,  Train Acc: 90.62%,  Val Loss:  0.27,  Val Acc: 90.12%,  Time: 0:04:27 
Iter:   5100,  Train Loss:  0.21,  Train Acc: 92.19%,  Val Loss:  0.26,  Val Acc: 90.48%,  Time: 0:04:35 *
Iter:   5200,  Train Loss:  0.26,  Train Acc: 90.62%,  Val Loss:  0.26,  Val Acc: 90.52%,  Time: 0:04:43 *
Iter:   5300,  Train Loss:  0.23,  Train Acc: 90.62%,  Val Loss:  0.28,  Val Acc: 89.87%,  Time: 0:04:49 
Iter:   5400,  Train Loss:  0.31,  Train Acc: 90.62%,  Val Loss:  0.28,  Val Acc: 89.87%,  Time: 0:04:55 
Iter:   5500,  Train Loss:  0.28,  Train Acc: 87.50%,  Val Loss:  0.27,  Val Acc: 90.37%,  Time: 0:05:01 
Iter:   5600,  Train Loss:   0.3,  Train Acc: 89.06%,  Val Loss:  0.27,  Val Acc: 90.63%,  Time: 0:05:07 
Iter:   5700,  Train Loss:  0.13,  Train Acc: 95.31%,  Val Loss:  0.28,  Val Acc: 89.85%,  Time: 0:05:13 
Iter:   5800,  Train Loss: 0.042,  Train Acc: 100.00%,  Val Loss:  0.27,  Val Acc: 90.00%,  Time: 0:05:19 
Iter:   5900,  Train Loss:  0.25,  Train Acc: 89.06%,  Val Loss:  0.26,  Val Acc: 90.83%,  Time: 0:05:25 
Iter:   6000,  Train Loss:  0.18,  Train Acc: 93.75%,  Val Loss:  0.26,  Val Acc: 90.35%,  Time: 0:05:31 
Iter:   6100,  Train Loss:  0.14,  Train Acc: 96.88%,  Val Loss:  0.27,  Val Acc: 90.20%,  Time: 0:05:36 
Iter:   6200,  Train Loss:  0.11,  Train Acc: 96.88%,  Val Loss:  0.27,  Val Acc: 90.53%,  Time: 0:05:42 
No optimization for a long time, auto-stopping...
Test Loss:  0.26,  Test Acc: 90.72%
Precision, Recall and F1-Score...
              precision    recall  f1-score   support

       World     0.9300    0.9016    0.9156      1900
      Sports     0.9446    0.9789    0.9615      1900
    Business     0.8752    0.8674    0.8713      1900
    Sci/Tech     0.8783    0.8811    0.8797      1900

    accuracy                         0.9072      7600
   macro avg     0.9070    0.9072    0.9070      7600
weighted avg     0.9070    0.9072    0.9070      7600

Confusion Matrix...
[[1713   63   65   59]
 [  15 1860   17    8]
 [  63   24 1648  165]
 [  51   22  153 1674]]
Time usage: 0:00:01
